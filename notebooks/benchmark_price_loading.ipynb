{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark: Parquet vs DuckDB for Price Loading\n",
    "\n",
    "This notebook analyzes whether replacing DuckDB with direct PyArrow Parquet loading\n",
    "would improve performance for `load_all_prices()` and `load_prices_matrix()`.\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "| Scenario | Expected Winner | Why |\n",
    "|----------|-----------------|-----|\n",
    "| Full file load (no date filter) | PyArrow | No SQL parse overhead, zero-copy columns |\n",
    "| Date-filtered load (small range) | DuckDB | Pushdown predicate to Parquet row groups |\n",
    "| Date-filtered load (most data) | PyArrow | Filter overhead < DuckDB overhead |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:48:00.891943Z",
     "iopub.status.busy": "2026-01-27T22:48:00.891667Z",
     "iopub.status.idle": "2026-01-27T22:48:00.993295Z",
     "shell.execute_reply": "2026-01-27T22:48:00.992911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using prices file: ../data/prices.parquet\n",
      "File exists: True\n",
      "File size: 34.7 MB\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc\n",
    "from datetime import date\n",
    "\n",
    "# Find the prices parquet file\n",
    "PRICES_FILE = \"../data/prices.parquet\"\n",
    "if not os.path.exists(PRICES_FILE):\n",
    "    # Try alternate location\n",
    "    PRICES_FILE = \"data/prices.parquet\"\n",
    "    \n",
    "print(f\"Using prices file: {PRICES_FILE}\")\n",
    "print(f\"File exists: {os.path.exists(PRICES_FILE)}\")\n",
    "if os.path.exists(PRICES_FILE):\n",
    "    print(f\"File size: {os.path.getsize(PRICES_FILE) / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Measure Current DuckDB Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:48:01.008563Z",
     "iopub.status.busy": "2026-01-27T22:48:01.008425Z",
     "iopub.status.idle": "2026-01-27T22:48:11.157539Z",
     "shell.execute_reply": "2026-01-27T22:48:11.157067Z"
    }
   },
   "outputs": [],
   "source": [
    "from specparser.amt import load_all_prices, load_prices_matrix, clear_prices_dict, clear_prices_matrix\n",
    "\n",
    "# Warm up (first call may include import overhead)\n",
    "clear_prices_dict()\n",
    "_ = load_all_prices(PRICES_FILE)\n",
    "clear_prices_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:48:11.158831Z",
     "iopub.status.busy": "2026-01-27T22:48:11.158721Z",
     "iopub.status.idle": "2026-01-27T22:48:20.082293Z",
     "shell.execute_reply": "2026-01-27T22:48:20.081828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_all_prices (no filter): 8.921s, 8,489,913 keys\n"
     ]
    }
   ],
   "source": [
    "# Benchmark load_all_prices (no filter)\n",
    "clear_prices_dict()\n",
    "t0 = time.perf_counter()\n",
    "prices_dict = load_all_prices(PRICES_FILE)\n",
    "t1 = time.perf_counter()\n",
    "duckdb_load_all_no_filter = t1 - t0\n",
    "n_keys = len(prices_dict)\n",
    "print(f\"load_all_prices (no filter): {duckdb_load_all_no_filter:.3f}s, {n_keys:,} keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:48:20.083364Z",
     "iopub.status.busy": "2026-01-27T22:48:20.083284Z",
     "iopub.status.idle": "2026-01-27T22:48:21.085877Z",
     "shell.execute_reply": "2026-01-27T22:48:21.085366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_all_prices (3yr filter): 1.000s, 977,163 keys\n",
      "Filter ratio: 11.5% of data\n"
     ]
    }
   ],
   "source": [
    "# Benchmark load_all_prices (with 3-year date filter)\n",
    "clear_prices_dict()\n",
    "t0 = time.perf_counter()\n",
    "prices_dict_filtered = load_all_prices(PRICES_FILE, \"2022-01-01\", \"2024-12-31\")\n",
    "t1 = time.perf_counter()\n",
    "duckdb_load_all_3yr_filter = t1 - t0\n",
    "n_keys_filtered = len(prices_dict_filtered)\n",
    "print(f\"load_all_prices (3yr filter): {duckdb_load_all_3yr_filter:.3f}s, {n_keys_filtered:,} keys\")\n",
    "print(f\"Filter ratio: {n_keys_filtered/n_keys*100:.1f}% of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:48:21.087075Z",
     "iopub.status.busy": "2026-01-27T22:48:21.086983Z",
     "iopub.status.idle": "2026-01-27T22:48:27.301268Z",
     "shell.execute_reply": "2026-01-27T22:48:27.300769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_prices_matrix (no filter): 6.212s\n",
      "Matrix shape: (4850, 6649) (4850 ticker|fields x 6649 dates)\n",
      "Memory: 246.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Benchmark load_prices_matrix (no filter)\n",
    "clear_prices_matrix()\n",
    "t0 = time.perf_counter()\n",
    "pm = load_prices_matrix(PRICES_FILE)\n",
    "t1 = time.perf_counter()\n",
    "duckdb_load_matrix_no_filter = t1 - t0\n",
    "print(f\"load_prices_matrix (no filter): {duckdb_load_matrix_no_filter:.3f}s\")\n",
    "print(f\"Matrix shape: {pm.price_matrix.shape} ({pm.n_rows} ticker|fields x {pm.n_cols} dates)\")\n",
    "print(f\"Memory: {pm.price_matrix.nbytes / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Profile Where Time Goes (DuckDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:48:27.302378Z",
     "iopub.status.busy": "2026-01-27T22:48:27.302301Z",
     "iopub.status.idle": "2026-01-27T22:48:37.093829Z",
     "shell.execute_reply": "2026-01-27T22:48:37.093363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB query + fetchall: 2.604s, 8,489,913 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python dict building: 7.178s\n",
      "\n",
      "Breakdown:\n",
      "  DuckDB query: 29.2%\n",
      "  Python loop:  80.5%\n"
     ]
    }
   ],
   "source": [
    "# Profile DuckDB query vs Python loop\n",
    "\n",
    "# DuckDB query time\n",
    "con = duckdb.connect()\n",
    "t0 = time.perf_counter()\n",
    "result = con.execute(f\"SELECT ticker, field, date, value FROM '{PRICES_FILE}'\").fetchall()\n",
    "t1 = time.perf_counter()\n",
    "duckdb_query_time = t1 - t0\n",
    "con.close()\n",
    "print(f\"DuckDB query + fetchall: {duckdb_query_time:.3f}s, {len(result):,} rows\")\n",
    "\n",
    "# Python dict building time\n",
    "t0 = time.perf_counter()\n",
    "test_dict = {}\n",
    "for ticker, field, dt, value in result:\n",
    "    key = f\"{ticker}|{field}|{dt}\"\n",
    "    test_dict[key] = str(value)\n",
    "t1 = time.perf_counter()\n",
    "python_dict_time = t1 - t0\n",
    "print(f\"Python dict building: {python_dict_time:.3f}s\")\n",
    "\n",
    "print(f\"\\nBreakdown:\")\n",
    "print(f\"  DuckDB query: {duckdb_query_time/duckdb_load_all_no_filter*100:.1f}%\")\n",
    "print(f\"  Python loop:  {python_dict_time/duckdb_load_all_no_filter*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Implement PyArrow Alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:48:37.094911Z",
     "iopub.status.busy": "2026-01-27T22:48:37.094827Z",
     "iopub.status.idle": "2026-01-27T22:48:37.097470Z",
     "shell.execute_reply": "2026-01-27T22:48:37.097133Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_all_prices_arrow(\n",
    "    prices_parquet: str,\n",
    "    start_date: str | None = None,\n",
    "    end_date: str | None = None\n",
    ") -> dict[str, str]:\n",
    "    \"\"\"Load prices using PyArrow (benchmark version).\"\"\"\n",
    "    \n",
    "    # Read parquet\n",
    "    table = pq.read_table(prices_parquet)\n",
    "    \n",
    "    # Optional date filter - need to convert string dates to date objects for Arrow comparison\n",
    "    if start_date or end_date:\n",
    "        conditions = []\n",
    "        if start_date:\n",
    "            start_dt = date.fromisoformat(start_date)\n",
    "            conditions.append(pc.greater_equal(table['date'], pa.scalar(start_dt, type=pa.date32())))\n",
    "        if end_date:\n",
    "            end_dt = date.fromisoformat(end_date)\n",
    "            conditions.append(pc.less_equal(table['date'], pa.scalar(end_dt, type=pa.date32())))\n",
    "        if len(conditions) == 2:\n",
    "            mask = pc.and_(conditions[0], conditions[1])\n",
    "        else:\n",
    "            mask = conditions[0]\n",
    "        table = table.filter(mask)\n",
    "    \n",
    "    # Build dict using Arrow compute (vectorized string concat)\n",
    "    # Convert date to string first\n",
    "    date_str = pc.strftime(table['date'], '%Y-%m-%d')\n",
    "    \n",
    "    # Build composite key: ticker|field|date\n",
    "    keys = pc.binary_join_element_wise(\n",
    "        pc.binary_join_element_wise(table['ticker'], table['field'], '|'),\n",
    "        date_str,\n",
    "        '|'\n",
    "    )\n",
    "    values = pc.cast(table['value'], pa.string())\n",
    "    \n",
    "    # Convert to Python dict\n",
    "    return dict(zip(keys.to_pylist(), values.to_pylist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:48:37.098490Z",
     "iopub.status.busy": "2026-01-27T22:48:37.098417Z",
     "iopub.status.idle": "2026-01-27T22:48:47.689613Z",
     "shell.execute_reply": "2026-01-27T22:48:47.689212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyArrow read_table: 0.105s, 8,489,913 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrow compute (keys/values): 3.710s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrow to Python lists: 5.049s\n",
      "Dict creation: 1.724s\n",
      "\n",
      "Total PyArrow: 10.588s\n"
     ]
    }
   ],
   "source": [
    "# Profile PyArrow approach - break down steps\n",
    "\n",
    "# Step 1: Read parquet\n",
    "t0 = time.perf_counter()\n",
    "table = pq.read_table(PRICES_FILE)\n",
    "t1 = time.perf_counter()\n",
    "arrow_read_time = t1 - t0\n",
    "print(f\"PyArrow read_table: {arrow_read_time:.3f}s, {table.num_rows:,} rows\")\n",
    "\n",
    "# Step 2: String operations\n",
    "t0 = time.perf_counter()\n",
    "date_str = pc.strftime(table['date'], '%Y-%m-%d')\n",
    "keys = pc.binary_join_element_wise(\n",
    "    pc.binary_join_element_wise(table['ticker'], table['field'], '|'),\n",
    "    date_str,\n",
    "    '|'\n",
    ")\n",
    "values = pc.cast(table['value'], pa.string())\n",
    "t1 = time.perf_counter()\n",
    "arrow_compute_time = t1 - t0\n",
    "print(f\"Arrow compute (keys/values): {arrow_compute_time:.3f}s\")\n",
    "\n",
    "# Step 3: Convert to Python dict\n",
    "t0 = time.perf_counter()\n",
    "keys_list = keys.to_pylist()\n",
    "values_list = values.to_pylist()\n",
    "t1 = time.perf_counter()\n",
    "arrow_to_python_time = t1 - t0\n",
    "print(f\"Arrow to Python lists: {arrow_to_python_time:.3f}s\")\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "result_dict = dict(zip(keys_list, values_list))\n",
    "t1 = time.perf_counter()\n",
    "dict_creation_time = t1 - t0\n",
    "print(f\"Dict creation: {dict_creation_time:.3f}s\")\n",
    "\n",
    "arrow_total = arrow_read_time + arrow_compute_time + arrow_to_python_time + dict_creation_time\n",
    "print(f\"\\nTotal PyArrow: {arrow_total:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Benchmark PyArrow vs DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:48:47.690729Z",
     "iopub.status.busy": "2026-01-27T22:48:47.690633Z",
     "iopub.status.idle": "2026-01-27T22:48:58.205461Z",
     "shell.execute_reply": "2026-01-27T22:48:58.204996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_all_prices_arrow (no filter): 10.513s, 8,489,913 keys\n"
     ]
    }
   ],
   "source": [
    "# Benchmark PyArrow (no filter)\n",
    "t0 = time.perf_counter()\n",
    "prices_dict_arrow = load_all_prices_arrow(PRICES_FILE)\n",
    "t1 = time.perf_counter()\n",
    "arrow_load_all_no_filter = t1 - t0\n",
    "print(f\"load_all_prices_arrow (no filter): {arrow_load_all_no_filter:.3f}s, {len(prices_dict_arrow):,} keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:48:58.206583Z",
     "iopub.status.busy": "2026-01-27T22:48:58.206501Z",
     "iopub.status.idle": "2026-01-27T22:48:59.397466Z",
     "shell.execute_reply": "2026-01-27T22:48:59.397110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_all_prices_arrow (3yr filter): 1.189s, 977,163 keys\n"
     ]
    }
   ],
   "source": [
    "# Benchmark PyArrow (3-year filter)\n",
    "t0 = time.perf_counter()\n",
    "prices_dict_arrow_filtered = load_all_prices_arrow(PRICES_FILE, \"2022-01-01\", \"2024-12-31\")\n",
    "t1 = time.perf_counter()\n",
    "arrow_load_all_3yr_filter = t1 - t0\n",
    "print(f\"load_all_prices_arrow (3yr filter): {arrow_load_all_3yr_filter:.3f}s, {len(prices_dict_arrow_filtered):,} keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:48:59.398708Z",
     "iopub.status.busy": "2026-01-27T22:48:59.398634Z",
     "iopub.status.idle": "2026-01-27T22:49:09.725266Z",
     "shell.execute_reply": "2026-01-27T22:49:09.724757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB keys: 8,489,913\n",
      "Arrow keys:  8,489,913\n",
      "Keys match:  True\n"
     ]
    }
   ],
   "source": [
    "# Verify correctness - keys should match\n",
    "clear_prices_dict()\n",
    "prices_dict_duckdb = load_all_prices(PRICES_FILE)\n",
    "\n",
    "# Compare key sets\n",
    "duckdb_keys = set(prices_dict_duckdb.keys())\n",
    "arrow_keys = set(prices_dict_arrow.keys())\n",
    "\n",
    "print(f\"DuckDB keys: {len(duckdb_keys):,}\")\n",
    "print(f\"Arrow keys:  {len(arrow_keys):,}\")\n",
    "print(f\"Keys match:  {duckdb_keys == arrow_keys}\")\n",
    "\n",
    "if duckdb_keys != arrow_keys:\n",
    "    print(f\"Only in DuckDB: {len(duckdb_keys - arrow_keys)}\")\n",
    "    print(f\"Only in Arrow: {len(arrow_keys - duckdb_keys)}\")\n",
    "    # Show sample differences\n",
    "    if duckdb_keys - arrow_keys:\n",
    "        print(f\"Sample DuckDB-only: {list(duckdb_keys - arrow_keys)[:3]}\")\n",
    "    if arrow_keys - duckdb_keys:\n",
    "        print(f\"Sample Arrow-only: {list(arrow_keys - duckdb_keys)[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:49:09.726385Z",
     "iopub.status.busy": "2026-01-27T22:49:09.726310Z",
     "iopub.status.idle": "2026-01-27T22:49:10.284723Z",
     "shell.execute_reply": "2026-01-27T22:49:10.284361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch: LAQ2007 Comdty|PX_LAST|2003-08-01\n",
      "  DuckDB: 1431.0\n",
      "  Arrow:  1431\n",
      "Mismatch: LPH2006 Comdty|PX_LAST|2004-07-13\n",
      "  DuckDB: 2356.0\n",
      "  Arrow:  2356\n",
      "Mismatch: LPK2023 Comdty|PX_LAST|2015-04-22\n",
      "  DuckDB: 6012.0\n",
      "  Arrow:  6012\n",
      "Value mismatches in first 10k: 967\n"
     ]
    }
   ],
   "source": [
    "# Compare values for matching keys\n",
    "if duckdb_keys == arrow_keys:\n",
    "    mismatches = 0\n",
    "    for key in list(duckdb_keys)[:10000]:  # Sample first 10k\n",
    "        if prices_dict_duckdb[key] != prices_dict_arrow[key]:\n",
    "            mismatches += 1\n",
    "            if mismatches <= 3:\n",
    "                print(f\"Mismatch: {key}\")\n",
    "                print(f\"  DuckDB: {prices_dict_duckdb[key]}\")\n",
    "                print(f\"  Arrow:  {prices_dict_arrow[key]}\")\n",
    "    print(f\"Value mismatches in first 10k: {mismatches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: PriceMatrix Alternative (PyArrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:49:10.285889Z",
     "iopub.status.busy": "2026-01-27T22:49:10.285804Z",
     "iopub.status.idle": "2026-01-27T22:49:10.290454Z",
     "shell.execute_reply": "2026-01-27T22:49:10.290120Z"
    }
   },
   "outputs": [],
   "source": [
    "from specparser.amt.prices import PriceMatrix\n",
    "\n",
    "_EPOCH = date(1970, 1, 1)\n",
    "\n",
    "def load_prices_matrix_arrow(\n",
    "    prices_parquet: str,\n",
    "    start_date: str | None = None,\n",
    "    end_date: str | None = None,\n",
    ") -> PriceMatrix:\n",
    "    \"\"\"Load prices into PriceMatrix using PyArrow.\"\"\"\n",
    "    \n",
    "    # Read parquet\n",
    "    table = pq.read_table(prices_parquet)\n",
    "    \n",
    "    # Optional date filter - need to convert string dates to date objects for Arrow comparison\n",
    "    if start_date or end_date:\n",
    "        conditions = []\n",
    "        if start_date:\n",
    "            start_dt = date.fromisoformat(start_date)\n",
    "            conditions.append(pc.greater_equal(table['date'], pa.scalar(start_dt, type=pa.date32())))\n",
    "        if end_date:\n",
    "            end_dt = date.fromisoformat(end_date)\n",
    "            conditions.append(pc.less_equal(table['date'], pa.scalar(end_dt, type=pa.date32())))\n",
    "        if len(conditions) == 2:\n",
    "            mask = pc.and_(conditions[0], conditions[1])\n",
    "        else:\n",
    "            mask = conditions[0]\n",
    "        table = table.filter(mask)\n",
    "    \n",
    "    if table.num_rows == 0:\n",
    "        return PriceMatrix(\n",
    "            price_matrix=np.empty((0, 0), dtype=np.float64),\n",
    "            ticker_field_to_row={},\n",
    "            date32_to_col=np.array([], dtype=np.int32),\n",
    "            min_date32=0,\n",
    "        )\n",
    "    \n",
    "    # Build ticker|field key column\n",
    "    ticker_field = pc.binary_join_element_wise(table['ticker'], table['field'], '|')\n",
    "    \n",
    "    # Get unique ticker|fields and dates\n",
    "    unique_tf = pc.unique(ticker_field).to_pylist()\n",
    "    unique_tf_sorted = sorted(unique_tf)\n",
    "    ticker_field_to_row = {tf: i for i, tf in enumerate(unique_tf_sorted)}\n",
    "    n_rows = len(unique_tf_sorted)\n",
    "    \n",
    "    # Convert dates to date32 (days since epoch)\n",
    "    epoch_ordinal = _EPOCH.toordinal()\n",
    "    dates_py = table['date'].to_pylist()\n",
    "    date32_values = np.array([d.toordinal() - epoch_ordinal for d in dates_py], dtype=np.int32)\n",
    "    \n",
    "    unique_date32 = sorted(set(date32_values))\n",
    "    date32_to_col_dict = {d: i for i, d in enumerate(unique_date32)}\n",
    "    n_cols = len(unique_date32)\n",
    "    \n",
    "    min_date32 = unique_date32[0]\n",
    "    max_date32 = unique_date32[-1]\n",
    "    n_calendar_days = max_date32 - min_date32 + 1\n",
    "    \n",
    "    # Build dense date32_to_col array\n",
    "    date32_to_col = np.full(n_calendar_days, -1, dtype=np.int32)\n",
    "    for d32, col in date32_to_col_dict.items():\n",
    "        date32_to_col[d32 - min_date32] = col\n",
    "    \n",
    "    # Build row indices for each entry\n",
    "    tf_list = ticker_field.to_pylist()\n",
    "    row_indices = np.array([ticker_field_to_row[tf] for tf in tf_list], dtype=np.int32)\n",
    "    col_indices = np.array([date32_to_col_dict[d32] for d32 in date32_values], dtype=np.int32)\n",
    "    \n",
    "    # Get values as float array\n",
    "    values = table['value'].to_numpy().astype(np.float64)\n",
    "    \n",
    "    # Fill price matrix using numpy advanced indexing (vectorized!)\n",
    "    price_matrix = np.full((n_rows, n_cols), np.nan, dtype=np.float64)\n",
    "    price_matrix[row_indices, col_indices] = values\n",
    "    \n",
    "    return PriceMatrix(\n",
    "        price_matrix=price_matrix,\n",
    "        ticker_field_to_row=ticker_field_to_row,\n",
    "        date32_to_col=date32_to_col,\n",
    "        min_date32=min_date32,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:49:10.291555Z",
     "iopub.status.busy": "2026-01-27T22:49:10.291471Z",
     "iopub.status.idle": "2026-01-27T22:49:18.893581Z",
     "shell.execute_reply": "2026-01-27T22:49:18.893022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_prices_matrix_arrow (no filter): 8.600s\n",
      "Matrix shape: (4850, 6649)\n"
     ]
    }
   ],
   "source": [
    "# Benchmark load_prices_matrix_arrow (no filter)\n",
    "t0 = time.perf_counter()\n",
    "pm_arrow = load_prices_matrix_arrow(PRICES_FILE)\n",
    "t1 = time.perf_counter()\n",
    "arrow_load_matrix_no_filter = t1 - t0\n",
    "print(f\"load_prices_matrix_arrow (no filter): {arrow_load_matrix_no_filter:.3f}s\")\n",
    "print(f\"Matrix shape: {pm_arrow.price_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:49:18.894615Z",
     "iopub.status.busy": "2026-01-27T22:49:18.894535Z",
     "iopub.status.idle": "2026-01-27T22:49:25.857324Z",
     "shell.execute_reply": "2026-01-27T22:49:25.856877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB matrix shape: (4850, 6649)\n",
      "Arrow matrix shape:  (4850, 6649)\n",
      "Shapes match: True\n",
      "Values match: True\n"
     ]
    }
   ],
   "source": [
    "# Verify PriceMatrix correctness\n",
    "clear_prices_matrix()\n",
    "pm_duckdb = load_prices_matrix(PRICES_FILE)\n",
    "\n",
    "print(f\"DuckDB matrix shape: {pm_duckdb.price_matrix.shape}\")\n",
    "print(f\"Arrow matrix shape:  {pm_arrow.price_matrix.shape}\")\n",
    "print(f\"Shapes match: {pm_duckdb.price_matrix.shape == pm_arrow.price_matrix.shape}\")\n",
    "\n",
    "if pm_duckdb.price_matrix.shape == pm_arrow.price_matrix.shape:\n",
    "    # Compare values (accounting for NaN)\n",
    "    close = np.allclose(pm_duckdb.price_matrix, pm_arrow.price_matrix, equal_nan=True)\n",
    "    print(f\"Values match: {close}\")\n",
    "    \n",
    "    if not close:\n",
    "        diff = np.abs(pm_duckdb.price_matrix - pm_arrow.price_matrix)\n",
    "        diff_mask = ~np.isnan(diff) & (diff > 1e-10)\n",
    "        print(f\"Number of differing values: {np.sum(diff_mask)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:49:25.858587Z",
     "iopub.status.busy": "2026-01-27T22:49:25.858505Z",
     "iopub.status.idle": "2026-01-27T22:49:25.862869Z",
     "shell.execute_reply": "2026-01-27T22:49:25.862543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BENCHMARK RESULTS\n",
      "======================================================================\n",
      "                      Function  DuckDB (s)  PyArrow (s)  Speedup Winner\n",
      "   load_all_prices (no filter)    8.921209    10.512742 0.848609 DuckDB\n",
      "  load_all_prices (3yr filter)    1.000249     1.188990 0.841259 DuckDB\n",
      "load_prices_matrix (no filter)    6.211921     8.599905 0.722324 DuckDB\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = {\n",
    "    'Function': [\n",
    "        'load_all_prices (no filter)',\n",
    "        'load_all_prices (3yr filter)',\n",
    "        'load_prices_matrix (no filter)',\n",
    "    ],\n",
    "    'DuckDB (s)': [\n",
    "        duckdb_load_all_no_filter,\n",
    "        duckdb_load_all_3yr_filter,\n",
    "        duckdb_load_matrix_no_filter,\n",
    "    ],\n",
    "    'PyArrow (s)': [\n",
    "        arrow_load_all_no_filter,\n",
    "        arrow_load_all_3yr_filter,\n",
    "        arrow_load_matrix_no_filter,\n",
    "    ],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df['Speedup'] = df['DuckDB (s)'] / df['PyArrow (s)']\n",
    "df['Winner'] = df.apply(lambda r: 'PyArrow' if r['Speedup'] > 1 else 'DuckDB', axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BENCHMARK RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(df.to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:49:25.863871Z",
     "iopub.status.busy": "2026-01-27T22:49:25.863780Z",
     "iopub.status.idle": "2026-01-27T22:49:25.866475Z",
     "shell.execute_reply": "2026-01-27T22:49:25.866184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(matplotlib not available - skipping chart)\n"
     ]
    }
   ],
   "source": [
    "# Visual comparison (requires matplotlib)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    x = np.arange(len(df))\n",
    "    width = 0.35\n",
    "\n",
    "    bars1 = ax.bar(x - width/2, df['DuckDB (s)'], width, label='DuckDB', color='steelblue')\n",
    "    bars2 = ax.bar(x + width/2, df['PyArrow (s)'], width, label='PyArrow', color='coral')\n",
    "\n",
    "    ax.set_ylabel('Time (seconds)')\n",
    "    ax.set_title('Price Loading: DuckDB vs PyArrow')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(['load_all_prices\\n(no filter)', 'load_all_prices\\n(3yr filter)', 'load_prices_matrix\\n(no filter)'])\n",
    "    ax.legend()\n",
    "\n",
    "    # Add speedup annotations\n",
    "    for i, (b1, b2, speedup) in enumerate(zip(bars1, bars2, df['Speedup'])):\n",
    "        max_height = max(b1.get_height(), b2.get_height())\n",
    "        ax.annotate(f'{speedup:.2f}x', \n",
    "                    xy=(i, max_height + 0.1),\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=10, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"(matplotlib not available - skipping chart)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis & Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:49:25.867501Z",
     "iopub.status.busy": "2026-01-27T22:49:25.867417Z",
     "iopub.status.idle": "2026-01-27T22:49:25.870253Z",
     "shell.execute_reply": "2026-01-27T22:49:25.869873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Average speedup: 0.80x\n",
      "\n",
      "Breakdown for load_all_prices (no filter):\n",
      "  DuckDB query + fetchall: 2.604s (29.2%)\n",
      "  Python dict building:    7.178s (80.5%)\n",
      "\n",
      "PyArrow breakdown:\n",
      "  read_table:     0.105s\n",
      "  Arrow compute:  3.710s\n",
      "  to_pylist:      5.049s\n",
      "  dict(zip):      1.724s\n",
      "\n",
      "======================================================================\n",
      "RECOMMENDATION\n",
      "======================================================================\n",
      "\n",
      "❌ KEEP DUCKDB\n",
      "   PyArrow is slower (speedup 0.80x).\n",
      "\n",
      "Notes:\n",
      "- These results may vary based on file size and data characteristics\n",
      "- DuckDB has better predicate pushdown for selective queries\n",
      "- PyArrow is better when reading most/all of the data\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "avg_speedup = df['Speedup'].mean()\n",
    "print(f\"\\nAverage speedup: {avg_speedup:.2f}x\")\n",
    "\n",
    "print(\"\\nBreakdown for load_all_prices (no filter):\")\n",
    "print(f\"  DuckDB query + fetchall: {duckdb_query_time:.3f}s ({duckdb_query_time/duckdb_load_all_no_filter*100:.1f}%)\")\n",
    "print(f\"  Python dict building:    {python_dict_time:.3f}s ({python_dict_time/duckdb_load_all_no_filter*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nPyArrow breakdown:\")\n",
    "print(f\"  read_table:     {arrow_read_time:.3f}s\")\n",
    "print(f\"  Arrow compute:  {arrow_compute_time:.3f}s\")\n",
    "print(f\"  to_pylist:      {arrow_to_python_time:.3f}s\")\n",
    "print(f\"  dict(zip):      {dict_creation_time:.3f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if avg_speedup >= 1.2:\n",
    "    print(f\"\\n✅ SWITCH TO PYARROW\")\n",
    "    print(f\"   Average speedup of {avg_speedup:.2f}x justifies the change.\")\n",
    "elif avg_speedup >= 1.0:\n",
    "    print(f\"\\n⚠️  MARGINAL IMPROVEMENT\")\n",
    "    print(f\"   Average speedup of {avg_speedup:.2f}x - consider if worth the code change.\")\n",
    "else:\n",
    "    print(f\"\\n❌ KEEP DUCKDB\")\n",
    "    print(f\"   PyArrow is slower (speedup {avg_speedup:.2f}x).\")\n",
    "\n",
    "print(\"\\nNotes:\")\n",
    "print(\"- These results may vary based on file size and data characteristics\")\n",
    "print(\"- DuckDB has better predicate pushdown for selective queries\")\n",
    "print(\"- PyArrow is better when reading most/all of the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T22:49:25.871163Z",
     "iopub.status.busy": "2026-01-27T22:49:25.871085Z",
     "iopub.status.idle": "2026-01-27T22:49:26.660334Z",
     "shell.execute_reply": "2026-01-27T22:49:26.659821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated dict memory usage:\n",
      "  DuckDB result: ~1350.7 MB\n",
      "  Arrow result:  ~1350.7 MB\n",
      "\n",
      "PriceMatrix memory:\n",
      "  Matrix array: 246.0 MB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Approximate memory usage\n",
    "duckdb_dict_size = sys.getsizeof(prices_dict_duckdb)\n",
    "arrow_dict_size = sys.getsizeof(prices_dict_arrow)\n",
    "\n",
    "# For dicts, need to also count keys and values\n",
    "duckdb_total = duckdb_dict_size + sum(sys.getsizeof(k) + sys.getsizeof(v) for k, v in list(prices_dict_duckdb.items())[:1000]) / 1000 * len(prices_dict_duckdb)\n",
    "arrow_total = arrow_dict_size + sum(sys.getsizeof(k) + sys.getsizeof(v) for k, v in list(prices_dict_arrow.items())[:1000]) / 1000 * len(prices_dict_arrow)\n",
    "\n",
    "print(f\"Estimated dict memory usage:\")\n",
    "print(f\"  DuckDB result: ~{duckdb_total/1024/1024:.1f} MB\")\n",
    "print(f\"  Arrow result:  ~{arrow_total/1024/1024:.1f} MB\")\n",
    "\n",
    "print(f\"\\nPriceMatrix memory:\")\n",
    "print(f\"  Matrix array: {pm_duckdb.price_matrix.nbytes/1024/1024:.1f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
